# project three plan notes
##### created: apr 15, 2024

## ideal backend tech stack (high-level)

- language:
  - C++
  - (& C) 
- model: deep learning network models/algorithms
  - network graphs
    - graph partitioning
    - tensor sharding
    - ^current and next-gen?
  - what do deep learning engineers need for their software? 
- compiler: performance optimizations
  - XLA
  - (& OpenXLA, TVM, MLIR, LLVM, OpenAI Triton)
  - performance tuning & analysis
  - debugging, performance, testing
  - what makes a deep learning compiler?
- ML frameworks:
  - JAX
    - research its APIs 
  - (& TensorFlow, PyTorch)
  - e.g. what is contributing to these like?
- ISA: (GPU/GPU architecture e.g. SIMT, etc.) (backend codegen)
  - CUDA
  - & OpenCL
  - (& OpenGL)
  - what do architects need?
- cloud distribution at scale: (training & inference)
  - is there a nvidia cloud platform?
  - (& Modular)
  - (etc.)  

- next steps:
  - research how nvcc and ptx fit into this
  - re-plan project two so i can get here
  - tune project one page to lead to here
